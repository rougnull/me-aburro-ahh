# NeuroMechFly: Differentiable Embodied Neuroscience

Complete neural-driven fly simulation with **end-to-end learning via backpropagation through time (BPTT)**.

Integrates:
- Real FlyWire connectome data
- Differentiable spiking neural networks (PyTorch)
- Embodied physics simulation (NeuroMechFly interface)
- Task-based optimization (navigation, energy efficiency)

## What is NeuroMechFly DMN?

**DMN = Differentiable Mechanical Networks**

This framework transforms fixed-parameter simulation into **learning systems** that optimize neural circuits for behavioral tasks:

```
NeuroMechFly Physics Engine â†â†’ Embodied Environment
              â†‘                        â†‘
              â”‚                        â”‚
         Motor Commands â†â†’ Differentiable Neural Circuit
              â†‘                        â†‘
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   Backpropagation Through Time
                        (Auto-differentiation)
                              â†“
                    Learn Synaptic Weights
                    Minimize: Distance to Goal
                             + Energy Cost
                             + Sparsity Loss
```

**Key Innovation**: Gradient descent discovers what neural mechanisms are necessary to navigate, solving the **inverse problem** of neurobiology.

## Features

### Neural Substrate
- **50 Olfactory Receptor Neurons (ORN)**: Gaussian tuning curves sensing odor gradient
- **2000 Kenyon Cells (KC)**: Sparse coding with random connectivity  
- **34 Mushroom Body Output Neurons (MBON)**: Linear summation of KC activity
- **10 Descending Neurons (DN)**: Motor command output
- **Biophysic LIF Model**: Leaky integrate-and-fire with realistic reset dynamics

### Body Model
- **3D Skeleton**: Head, thorax, abdomen
- **6 Legs**: 3 segments each with forward kinematics
- **2 Wings**: Visualization only
- **Tripod Gait CPG**: Central Pattern Generator at 10 Hz
- **Ground Contact Physics**: Foot contact detection and friction

### Environment
- **100Ã—100Ã—50 mm Arena**: Bounded 3D space
- **Gaussian Odor Gradient**: Centered at [50, 50, 0] mm
- **Diffusion Simulation**: Exponential falloff with distance

## Installation & Setup

### Step 1: PyTorch (2 min)
```bash
# CPU version (no GPU needed)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu

# Or GPU version for 10x speedup
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### Step 2: Dependencies (1 min)
```bash
pip install numpy scipy scikit-learn networkx h5py pyyaml matplotlib
```

### Step 3: Verify Setup (2 min)
```bash
python dmn_verify_setup.py
```

## Quick Start - Train Embodied DMN

### Basic Training (5 min on CPU, 30 sec on GPU)
```bash
# Train for 20 episodes (default)
python train_embodied_dmn.py --num-episodes 20

# Shows real-time loss, metrics, and results
```

Expected output:
```
Episode  1/20 | Loss:   12.3456 | Nav:    10.2341 | Energy:     0.0145
Episode  5/20 | Loss:    8.1234 | Nav:     7.0234 | Energy:     0.0089
Episode 20/20 | Loss:    2.1234 | Nav:     1.9876 | Energy:     0.0034

Final Trajectory Metrics:
  final_distance_to_goal: 2.3400
  mean_distance_to_goal: 15.4200
  total_distance_traveled: 45.2300

âœ“ Results saved to embodied_training_results/
```

### Advanced Training with Custom Parameters
```bash
# Emphasize energy efficiency
python train_embodied_dmn.py \
  --num-episodes 50 \
  --learning-rate 0.001 \
  --nav-weight 1.0 \
  --energy-weight 0.5

# Or focus on pure navigation
python train_embodied_dmn.py \
  --num-episodes 100 \
  --learning-rate 0.0001 \
  --nav-weight 2.0 \
  --energy-weight 0.01
```

## What Gets Learned?

The training process learns:

1. **Synaptic Weights** (ORNâ†’PN, PNâ†’KC, KCâ†’MBON, MBONâ†’DN)
   - Which connections matter for navigation
   - How strongly to weight inputs

2. **Neuron Time Constants** (Ï„)
   - How fast neurons integrate input
   - Balance between fast reactions and filtering

3. **Motor Encoding** (DNâ†’velocity mapping)
   - What DN spike patterns produce effective movement
   - Emergent motor strategies

**All optimized via gradient descent to minimize task loss:**
- Distance to goal
- Energy expenditure
- Sparse representation maintenance

## Project Structure

```
NeuroMechFly Sim/
â”œâ”€â”€ connectome/                 # FlyWire integration
â”‚   â”œâ”€â”€ fetch_data.py          # Load connectome data
â”‚   â”œâ”€â”€ adjacency_matrix.py    # Create learnable weights
â”‚   â””â”€â”€ cell_types.yaml        # Neuron reference
â”‚
â”œâ”€â”€ simulation/
â”‚   â”œâ”€â”€ mechanism.py           # Differentiable LIF neurons (PyTorch)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ... (existing files)
â”‚
â”œâ”€â”€ training/                  # Learning & optimization
â”‚   â”œâ”€â”€ loss_functions.py      # Task objectives
â”‚   â”œâ”€â”€ optimizer.py           # BPTT training loop
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ core/                      # NeuroMechFly physics
â”‚   â”œâ”€â”€ simulation.py          # Main loop
â”‚   â”œâ”€â”€ environment.py         # Arena & odor
â”‚   â””â”€â”€ ... (existing files)
â”‚
â”œâ”€â”€ brain/                     # Neural circuits
â”‚   â””â”€â”€ olfactory_circuit.py   # Biophysical LIF model
â”‚
â”œâ”€â”€ body/                      # Embodied control
â”‚   â””â”€â”€ realistic_body.py      # 3D skeleton kinematics
â”‚
â”œâ”€â”€ train_embodied_dmn.py      # Main training script â† START HERE
â”œâ”€â”€ dmn_embodied_integration.py # DMN â†” Physics adapter
â”œâ”€â”€ dmn_verify_setup.py        # Dependency checker
â””â”€â”€ README.md                  # This file
```

## How DMN Works

### The Learning Loop

```
1. ROLLOUT (Closed-loop simulation)
   â”œâ”€ Get odor observation from arena
   â”œâ”€ Forward pass through neural circuit
   â”œâ”€ Convert DN spikes to motor commands
   â”œâ”€ Update physics (NeuroMechFly)
   â””â”€ Record: positions, velocities, neural activity
   
2. COMPUTE LOSS
   â”œâ”€ Distance from fly to goal
   â”œâ”€ Energy cost of movement
   â”œâ”€ KC sparsity penalty
   â””â”€ Activity regularization
   
3. BACKPROPAGATION (BPTT)
   â”œâ”€ Gradients flow backward through 5000 timesteps
   â”œâ”€ Compute âˆ‚loss/âˆ‚w for all learnable weights
   â”œâ”€ Update synaptic weights via gradient descent
   â””â”€ Update neuron time constants
   
4. REPEAT for next episode
```

### Key Technical Points

**Surrogate Gradients**: Spikes are discrete (0/1) but we need differentiable gradients.
- Forward: Step function (actual spike yes/no)
- Backward: Smooth sigmoid (allows gradient flow)

**Connectivity Masks**: Preserve connectome structure while learning weights.
- Which synapses can exist: FIXED from FlyWire
- Synaptic strength: LEARNED via BPTT

**Multi-Task Optimization**: Trade-offs between objectives.
```python
Loss = 1.0 Ã— distance_to_goal    # Primary task
     + 0.1 Ã— movement_cost        # Energy efficiency  
     + 0.01 Ã— sparsity_violation  # Maintain sparse KC
     + 0.001 Ã— firing_rate_excess # Prevent pathology
```

## Interpreting Results

After training, you'll see in `embodied_training_results/training_results.json`:

```json
{
  "training_losses": [
    {
      "total": 12.3456,      // â† Should decrease over episodes
      "nav_distance": 10.234, // Decreased = learning to navigate
      "energy": 0.0145,       // Energy cost (lower = efficient)
      ...
    },
    ...
  ],
  "final_metrics": {
    "final_distance_to_goal": 2.34,    // â† How close did it get?
    "mean_distance_to_goal": 15.42,    // Average distance
    "total_distance_traveled": 45.23   // How much did it explore?
  }
}
```

**Good training**: 
- Loss decreases smoothly
- Final distance < 5mm (from 50mm goal)
- Mean distance drops significantly

## Research Applications

### 1. Reverse Engineering
Learn what circuit mechanisms are **necessary** for observed behaviors.

### 2. Developmental Studies  
How do circuits learn navigation skills?

### 3. Counterfactual Analysis
What if connectome was modified? Does learning compensate?

### 4. Neuromorphic Hardware
Export learned weights to Intel Loihi, BrainScaleS

## Technical Details

### Neural Circuit Architecture

```
Sensory Input (Odor)
    â†“ (50 Ã— 50 weight matrix)
ORN Layer (50 neurons) - Ï„=15ms, Î¸=-50mV
    â†“ (50 Ã— 50 weight matrix)
PN Layer (50 neurons) - Ï„=15ms, Î¸=-50mV [Learnable Ï„]
    â†“ (50 Ã— 2000 sparse mask, 2% connectivity)
KC Layer (2000 neurons) - Ï„=20ms, Î¸=-50mV [Learnable Ï„]
    â†“ (2000 Ã— 50 convergent)
MBON Layer (50 neurons) - Ï„=25ms, Î¸=-50mV [Learnable Ï„, weights]
    â†“ (50 Ã— 10 dense)
DN Layer (10 neurons) - Ï„=30ms, Î¸=-50mV [Learnable Ï„, weights]
    â†“ (10-dim spike output)
Motor Commands (velocity, turning, ...)
```

### LIF Neuron Dynamics

Each neuron computed as:
```
V[t+1] = Î±Â·V[t] + (1-Î±)Â·I_syn[t]

where:
  Î± = exp(-Î”t/Ï„)          Decay factor
  V = Membrane potential (mV)
  Ï„ = Time constant (ms)    â† Learnable
  I_syn = Weighted spike input
  
Spike generated if V > Î¸ (threshold, learnable)
After spike: V â† V_reset = -70mV
```

### Backprop Through Time (BPTT)

For a 5000-step episode:
```python
# Forward pass (accumulate loss)
total_loss = 0
for step in range(5000):
    observations = env.get_odor()
    neural_output = circuit(observations)
    motor_cmd = decode_motor(neural_output)
    env.step(motor_cmd)
    loss_step = loss_fn(trajectory_so_far)
    total_loss += loss_step

# Backward pass (compute gradients)
total_loss.backward()  # PyTorch autograd computes âˆ‚loss/âˆ‚w for ALL 5000 steps

# Update ALL parameters
optimizer.step()
```

**Key**: Gradients flow backward through entire episode, not just per-timestep.

## Dependencies

| Package | Purpose | Version |
|---------|---------|---------|
| `torch` | Auto-differentiation, GPU support | â‰¥2.0.0 |
| `numpy` | Numerical computation | â‰¥1.22 |
| `scipy` | Scientific math (sparse matrices) | â‰¥1.10 |
| `scikit-learn` | ML utilities, UMAP | â‰¥1.2 |
| `networkx` | Graph analysis | â‰¥3.0 |
| `h5py` | Data storage (HDF5) | â‰¥3.8 |
| `pyyaml` | Config parsing | â‰¥6.0 |
| `matplotlib` | Visualization | â‰¥3.5 |

## Troubleshooting

### "CUDA out of memory"
```bash
# Use CPU instead
python train_embodied_dmn.py --num-episodes 10
```

### "Module not found: connectome"
```bash
# Make sure you're in the project root
cd "NeuroMechFly Sim"
python train_embodied_dmn.py
```

### "Loss doesn't decrease"
```bash
# Try higher learning rate
python train_embodied_dmn.py --learning-rate 0.01

# Or train longer
python train_embodied_dmn.py --num-episodes 100
```

### "Import error for NeuroMechFly components"
```bash
# Verify all submodules exist
python dmn_verify_setup.py
```

## References

**Differentiable Spiking Networks**:
- Zenke & Ganguli (2018) "SuperSpike: Supervised learning in multilayer spiking neural networks"
- Bellec et al. (2020) "A Solution to the Learning Problem with Spiking Neurons"

**Connectomics**:
- Bates et al. (2020) "The connectome of the Drosophila central brain at synaptic resolution"
- Zheng et al. (2020) "A Complete Electron Microscopy Volume of the Brain of a Larval Zebrafish"

**Embodied AI**:
- Marblestone et al. (2016) "Toward an Integration of Deep Learning and Neuroscience"
- Caruana et al. (2021) "Meta-Learning in Neural Networks: A Survey"

## Citation

If you use this framework in your research, please cite:

```bibtex
@software{neuromechfly_dmn,
  title={NeuroMechFly: Differentiable Embodied Neuroscience Framework},
  author={Your Name},
  year={2024},
  note={Combines spiking neural networks with embodied physics simulation}
}
```

## License

MIT License - See LICENSE file for details

## Authors

Developed as a research framework for embodied neuroscience and neuromorphic computing.

---

**Ready to train?**

```bash
python train_embodied_dmn.py --num-episodes 20
```

Start here. See what your network learns. ğŸ§ ğŸ¤–

```
Odor (Arena) â†’ ORNs (sensores) 
            â†“
            PNs (procesamiento primario)
            â†“
            KCs (aprendizaje asociativo - Mushroom Body)
            â†“
            MBONs (codificaciÃ³n de valencia)
            â†“
            DNs (comandos motores)
```

### 3. **HipÃ³tesis de Embodied Cognition**

Cuando conectas un cerebro virtual con un cuerpo fÃ­sico simulado, puedes probar si tu modelo neuronal puede genuinamente **controlar el comportamiento** considerando:
- Inercia del cuerpo
- FricciÃ³n con el terreno
- Respuesta no lineal de los actuadores
- RetroalimentaciÃ³n sensorial de propioceptores

## InstalaciÃ³n

### 1. Activar el entorno virtual

**En Windows (PowerShell):**
```powershell
cd "C:\Users\eduar\Documents\Workspace\NeuroMechFly Sim\proyecto_mosca"
..\venv\Scripts\Activate.ps1
```

**En Windows (CMD):**
```cmd
cd C:\Users\eduar\Documents\Workspace\NeuroMechFly Sim\proyecto_mosca
..\venv\Scripts\activate.bat
```

**En macOS/Linux:**
```bash
cd ~/NeuroMechFly Sim/proyecto_mosca
source ../venv/bin/activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

### 3. (Futuro) Instalar NeuroMechFly

Una vez disponible:
```bash
pip install neuromechfly
```

O desde fuente:
```bash
git clone https://github.com/NeLy-EPFL/NeuroMechFly.git
pip install -e NeuroMechFly/
```

## Uso

### Ejecutar simulaciÃ³n bÃ¡sica

```bash
python run_experiment.py --duration 60 --config config/environment.yaml
```

### ParÃ¡metros disponibles

- `--duration`: DuraciÃ³n de la simulaciÃ³n en segundos (default: 60)
- `--config`: Ruta al archivo de configuraciÃ³n principal (default: config/environment.yaml)
- `--verbose`: Mostrar mÃ¡s informaciÃ³n (optional)

### Salida

La simulaciÃ³n genera:
- `data/YYYYMMDD_HHMMSS/simulation_data.h5`: Datos crudos en formato HDF5
  - Trayectoria (x, y, z)
  - Spikes neuronales de cada capa
  - Inputs sensoriales (odor)
- `data/YYYYMMDD_HHMMSS/trajectory.png`: GrÃ¡fico de la trayectoria en la arena
- `data/YYYYMMDD_HHMMSS/neural_activity.png`: Actividad de neuronas descendentes
- `data/YYYYMMDD_HHMMSS/odor_response.png`: ConcentraciÃ³n de olor detectada

## PrÃ³ximos Pasos

### Fase 2: IntegraciÃ³n con NeuroMechFly Real

1. **Instalar NeuroMechFly**: Obtener y instalar la librerÃ­a completa
2. **Reemplazar mock en `body/fly_interface.py`**: Conectar con el simulador de fÃ­sica real
3. **Calibrar ganancias motoras**: Ajustar factores de conversiÃ³n entre actividad neural y comandos motores

### Fase 3: Implementar Aprendizaje

1. **STDP (Spike-Timing-Dependent Plasticity)**: En conexiones KC-MBON
2. **Refuerzo**: Recompensa cuando la mosca llega a la comida
3. **ExtinciÃ³n**: PÃ©rdida de aprendizaje sin recompensa

### Fase 4: ValidaciÃ³n BiolÃ³gica

1. Comparar patrones de movimiento con datos experimentales
2. Validar rangos de frecuencia de disparo neuronal
3. Reproducir comportamientos conocidos (quimiotaxis, trail-following, etc.)

## Referencias BiolÃ³gicas

- [NeuroMechFly: Flying Fruit Fly Embodied in Physics](https://www.biorxiv.org/content/10.1101/2022.09.21.508678v1)
- [A connectome of the adult fruit fly brain](https://elifesciences.org/articles/57443) (Connectome completo)
- [Neural circuits for sensory-motor behaviors](https://www.nature.com/articles/s41593-019-0505-2)

## Notas TÃ©cnicas

### SincronizaciÃ³n de Timesteps

Es crÃ­tico sincronizar los timesteps de:
- **MuJoCo (physics)**: ~1 ms (0.001s) tÃ­picamente
- **Brian2 (neural)** si usas: Debe ser divisor de MuJoCo
- **Rendering**: Independiente, puede ser menos frecuente

En `config/brain_params.yaml`:
```yaml
integration:
  dt: 0.0001  # 10x mÃ¡s rÃ¡pido que fÃ­sica â†’ 10 pasos neurales por paso de fÃ­sica
```

### Formato de Salida HDF5

DespuÃ©s de una simulaciÃ³n, puedes cargar los datos asÃ­:

```python
import h5py
import numpy as np

with h5py.File('data/20240214_120000/simulation_data.h5', 'r') as f:
    positions = np.array(f['position'])      # Shape: (steps, 3)
    dn_spikes = np.array(f['neural_spikes'])  # Variable
    odor_input = np.array(f['odor_input'])   # Shape: (steps,)
```

## Licencia

[Especificar despuÃ©s]

## Contacto

EnvÃ­a preguntas o sugerencias a [tu email]
